{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjnjMGEVn-XM",
        "outputId": "b300743a-b185-4872-e257-2f8bb1ac1fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What The ___ brown fox jumps over the lazy dog.\n",
            "Where The quick brown fox jumps ___ the lazy dog.\n",
            "What The quick brown fox ___ over the lazy dog.\n",
            "What This is a simple ___.\n",
            "Which This is ___ simple sentence.\n",
            "What This is a ___ sentence.\n",
            "What It contains various ___ of speech.\n",
            "Where It contains various parts ___ speech.\n",
            "Who ___ contains various parts of speech.\n",
            "Which ___ cat sat on the mat.\n",
            "Which The cat sat on ___ mat.\n",
            "What The cat ___ on the mat.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import random\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "# Download necessary NLTK resources (run this ONCE in your Colab notebook)\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "\n",
        "def generate_questions(text, num_questions=5):\n",
        "    \"\"\"Generates questions from a given text using POS tagging.\"\"\"\n",
        "\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    questions = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        words = word_tokenize(sentence)\n",
        "        tagged_words = pos_tag(words)\n",
        "\n",
        "        question_candidates = []\n",
        "\n",
        "        for i, (word, tag) in enumerate(tagged_words):\n",
        "            if tag.startswith('NN') or tag.startswith('JJ'):\n",
        "                question_candidates.append((\"What \" + sentence.replace(word, \"___\"), word))\n",
        "            elif tag.startswith('VB'):\n",
        "                question_candidates.append((\"What \" + sentence.replace(word, \"___\"), word))\n",
        "            elif tag == 'RB':\n",
        "                question_candidates.append((\"How \" + sentence.replace(word, \"___\"), word))\n",
        "            elif tag == 'PRP':\n",
        "                question_candidates.append((\"Who \" + sentence.replace(word, \"___\"), word))\n",
        "            elif tag == 'CD':\n",
        "                question_candidates.append((\"How many \" + sentence.replace(word, \"___\"), word))\n",
        "            elif tag == 'CC':\n",
        "                question_candidates.append((\"Which \" + sentence.replace(word, \"___\"), word))\n",
        "            elif tag == 'IN':\n",
        "                question_candidates.append((\"Where \" + sentence.replace(word, \"___\"), word))\n",
        "            elif tag == 'DT':\n",
        "                question_candidates.append((\"Which \" + sentence.replace(word, \"___\"), word))\n",
        "\n",
        "        if question_candidates:\n",
        "            num_to_generate = min(len(question_candidates), num_questions)\n",
        "            chosen_questions = random.sample(question_candidates, num_to_generate)\n",
        "            questions.extend([q[0] for q in chosen_questions])\n",
        "\n",
        "    return questions\n",
        "\n",
        "# Example usage:\n",
        "text = \"\"\"The quick brown fox jumps over the lazy dog. This is a simple sentence.  It contains various parts of speech. The cat sat on the mat.\"\"\"\n",
        "\n",
        "generated_questions = generate_questions(text, 3)\n",
        "for question in generated_questions:\n",
        "    print(question)\n"
      ]
    }
  ]
}